{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0a308-9854-4daa-b800-37e74b4a349c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyarrow\n",
    "!pip install tsfel\n",
    "!pip install imblearn\n",
    "!pip install lightgbm\n",
    "!pip install tensorflow\n",
    "!pip install catboost\n",
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc8b057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 04:51:43.081434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import boto3\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "#!pip install openpyxl\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.5f}'.format #evita que muestre notacion cientifica\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "nombre_carpeta = '../../data/2022'\n",
    "import sys\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.preprocessing.preprocessing  import llenar_val_vacios_str,llenar_val_vacios_ciclo,TsfelVars, ExtraVars,ToDummy, TeEncoder, CardinalityReducer\n",
    "from src.modeling.simple_models import ChangeTrendPercentajeIdentifierWide,ConstantConsumptionClassifierWide\n",
    "from src.modeling.supervised_models import LGBMModel, NNModel, LSTMNNModel\n",
    "from src.modeling.feature_selection import feature_selection_by_constant, feature_selection_by_boruta, feature_selection_by_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28396aa7",
   "metadata": {},
   "source": [
    "## CONTENIDO:\n",
    "* [Objetivo](#objetivo)\n",
    "* [Info Inicial](#info)\n",
    "* [Concatenar Archivos](#concatenar-archivos)\n",
    "* [Eliminar Gratuitos](#eliminar-gratuitos)\n",
    "* [Descargar CSV](#descargar-csv)\n",
    "* [Leer CSV concatenado](#leer-csv)\n",
    "* [Convertir Formato](#convertir-formato)\n",
    "* [Verificar Valores Nulos](#valores-nulos)\n",
    "* [Verificar Cantidad de Valores Nulos](#cantidad-nulos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a43370",
   "metadata": {},
   "source": [
    "## OBJETIVO <a class=\"anchor\" id=\"objetivo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f5652",
   "metadata": {},
   "source": [
    "1. EPMAPS: El objetivo es indentificar las pérdidas no técnicas en el área de agua\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e57e27",
   "metadata": {},
   "source": [
    "## INFO INICIAL <a class=\"anchor\" id=\"info\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc408aa6",
   "metadata": {},
   "source": [
    "1. Cuanta data hisotrica tenemos? del 01/2010 al 12/2017\n",
    "\n",
    "2. Periodicidad del consumo? Mensual\n",
    "\n",
    "3. Es la data Univariate o multivariate ? \n",
    "\n",
    "4. Cual es la frequencia en que se realizará la detección de anomalias (en tiempo real, cada hora, semanal, mensual)? TBD\n",
    "\n",
    "5. En que unidad se supone que debemos hacer la deteccion de anomalias? volumen robado por usuario, medidor con fraude (pendiente definir)....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cec4cc",
   "metadata": {},
   "source": [
    "## PROCESAR ARCHIVOS <a class=\"anchor\" id=\"procesar-archivos\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b98ee",
   "metadata": {},
   "source": [
    "**Obtener directorio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d0ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('iagua-quito')#iadbprod-ine-tsp-analyticaldata\n",
    "# prefix_objs = bucket.objects.filter(Prefix=\"EPMAPS/data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a07e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"\n",
    "    Download the contents of a folder directory\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "download_s3_folder('iagua-quito','datos/Datos 2022/','../../data/2022')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fbd61",
   "metadata": {},
   "source": [
    "#### Concatenar Archivos <a class=\"anchor\" id=\"concatenar-archivos\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e143494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desde el bucket\n",
    "%%time\n",
    "print('[INFO]...concatenando archivos')\n",
    "bucket_path = 's3://iadbprod-ine-tsp-analyticaldata/' \n",
    "df = pd.DataFrame()\n",
    "for obj in bucket.objects.filter(Prefix='EPMAPS/data/H'):\n",
    "    key = obj.key\n",
    "    print(bucket_path+key)\n",
    "    df_csv = pd.read_csv(bucket_path+key, sep='\\t')\n",
    "    df = df.append(pd.concat([df_csv], axis=0, ignore_index=True), ignore_index=True)\n",
    "print(df.shape)\n",
    "print('[INFO]...Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51512ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Desde la notebook\n",
    "nombre_carpeta = '../../data/2022'\n",
    "contenido = os.listdir(nombre_carpeta)\n",
    "df = pd.DataFrame()\n",
    "for elemento in contenido:\n",
    "    ruta_completa = os.path.join(nombre_carpeta, elemento)\n",
    "    if os.path.isfile(ruta_completa):  # miramos si es fichero\n",
    "        agregar = False\n",
    "        if elemento[-4:].lower()=='.csv':\n",
    "            df_in = pd.read_csv(ruta_completa, sep=';', \n",
    "                               encoding='latin-1', warn_bad_lines=True, error_bad_lines=False,\n",
    "                               lineterminator='\\n')\n",
    "            agregar = True\n",
    "        elif elemento[-5:].lower()=='.xlsx':\n",
    "            df_in = pd.read_excel(ruta_completa, engine='openpyxl')\n",
    "            agregar = True\n",
    "        if agregar:\n",
    "            df = df.append(pd.concat([df_in], axis=0, ignore_index=True), ignore_index=True)\n",
    "            print(ruta_completa)\n",
    "df.to_pickle(os.path.join(nombre_carpeta, 'df_raw.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe9b10",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Convertir Formato y Limpiar <a class=\"anchor\" id=\"convertir-formato\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657101c-aa6f-409b-ab0c-d5dc082285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.columns = df.columns.str.lower()\n",
    "df.rename(columns={\"cuenta contrato\": \"numcta\",\"feclvcálc\":\"mesfac\",\"instalación\":\"instalacion\"}, inplace=True)\n",
    "df['numcta'] = pd.to_numeric(df['numcta'], errors='coerce')\n",
    "df['instalacion'] = pd.to_numeric(df['instalacion'], errors='coerce')\n",
    "df = df[(~df['numcta'].isnull()) & (~df['mesfac'].isnull()) & (~df['instalacion'].isnull())]\n",
    "df['numcta'] = df['numcta'].astype(int)\n",
    "df['numcta'] = df['numcta'].astype('string[pyarrow]')\n",
    "df['instalacion'] = df['instalacion'].astype(int)\n",
    "df['instalacion'] = df['instalacion'].astype('string[pyarrow]')\n",
    "df['mesfac'] = df['mesfac'].astype('string[pyarrow]')\n",
    "df = df[ (df['mesfac'].str.startswith('2021')) | (df['mesfac'].str.startswith('2022')) ]\n",
    "\n",
    "df['year']=df['mesfac'].str[:4]\n",
    "df['mes']=df['mesfac'].str[5:7]\n",
    "df['mes'] = pd.to_numeric(df['mes'], errors='coerce')\n",
    "df = df[~df['mes'].isnull()]\n",
    "df['mes'] = df['mes'].astype(int)\n",
    "df = df[(df['mes']>=1) & (df['mes']<=12)]\n",
    "df['mes'] = df['mes'].astype('string[pyarrow]').str.zfill(2)\n",
    "df['date']= df['mes'].astype('str')+'-'+df['year'].astype('str')\n",
    "df.date = pd.to_datetime(df.date)\n",
    "\n",
    "#df['comp_zona'] = df.ciclo.astype(str) + df.sector.astype(str) + df.ruta.astype(str) + df.manzana.astype(str) + df.secuencia.astype(str)\n",
    "\n",
    "campos_nulos = ['cta.contr.', 'instal.', 'dpto', 'pue.sumin.', 'obj.conex.', 'diámetro', 'tp.tarifa', 'inst.pral.', 'lect. act.', 'lect. ant.', 'cons.med.', 'cons.fact.', 'cons.prom.', 'tip.factu.', 'notal', 'est.medido', 'clins', 'clag', 'ctasoloalc']\n",
    "campos_no_req = ['comp_zona','punto suminis.','obj.conexión','medidor','nombre completo','calle','ced.ruc.pasapor','telef.cliente','celular','caractpredio\\r','instal.pral.','cl.agrupación','ctas. solo alca','diam. conex. alc.','caractpredio','consumo promedio','nota de lectura','con agua','con alcanta','numerador','fact.discapa']\n",
    "df = df.drop(columns = campos_nulos + campos_no_req)\n",
    "\n",
    "campos_float = ['f.aguaprorrat','fact.alcantpror','prorrat. cargof','desc.anciano.ag','desc.anciano.al','desc.disc.agua','desc.disc.alcan','des.socio.agua','desc.soci.alcan','desc.parro.agua','desc.parro.alca','multasxcta','inter. mora','inter. financia','tasanomenclatur','corte','reconexión','instal. algua','instal. alcant','coactiva','otrosservicio','fact. agua','fact. alcantari']\n",
    "for col in campos_float:\n",
    "    df[col] = pd.to_numeric(df[col].str.replace(',','.'), errors='coerce',downcast='float')\n",
    "\n",
    "campos_int = ['piso','departamento','diám. conex. ap.','consumo promedo','lectura actual','lectura anterior','consumo medido','consumo facturado','fact.socioecono','cl.instalación']\n",
    "for col in campos_int:\n",
    "    df[col] = pd.to_numeric(df[col].astype('str').str.replace(',','.').str.extract('(\\d+)', expand=False), errors='coerce',downcast='unsigned').fillna(0).astype('int32')\n",
    "    \n",
    "#Datos categóricos\n",
    "cat_tipo_tarifa = ['DOM','COM','OFI','PUB','IND','MUN','SAL']\n",
    "df['tipo de tarifa'] = pd.Series(np.where(df['tipo de tarifa'].isin(cat_tipo_tarifa),df['tipo de tarifa'],None)).astype('category')\n",
    "cat_estado_medidor = ['En funcionamiento','En almacén Disponible','Robado','A revisar','En almacén no recuperable','En almacén','En almacén Chatarra','En almacén recuperable','Medidor al revés']\n",
    "df['estado medidor'] = pd.Series(np.where(df['estado medidor'].isin(cat_estado_medidor),df['estado medidor'],None)).astype('category')\n",
    "cat_tipo_fact = ['Real','Estimada']\n",
    "df['tipo facturación'] = pd.Series(np.where(df['tipo facturación'].isin(cat_tipo_fact),df['tipo facturación'],None)).astype('category')\n",
    "cat_cl_inst = [1,2,3,4]\n",
    "df['cl.instalación'] = pd.Series(np.where(df['cl.instalación'].isin(cat_cl_inst),df['cl.instalación'],None)).astype('category')\n",
    "df['ciclo'] = df['ciclo'].str.extract(r'([A-Z]0\\d{2})', expand=False).astype('category')\n",
    "df['ramo'] = df['ramo'].str.extract(r'([A-Z]{,3}\\_\\d{,2}\\_\\d{,2}|[A-Z]{,3})', expand=False).astype('category')\n",
    "df['código hidráulico'] = df['código hidráulico'].str.extract(r'(\\d{1,3}\\_\\d{1,3}\\_\\d{1,3}\\_\\d{1,3})', expand=False).astype('category')\n",
    "df['cargo fijo'] = pd.to_numeric(df['cargo fijo'].str.replace(',','.').str.extract('(\\d+\\.\\d+)', expand=False),errors='coerce',downcast='float')\n",
    "df['cargo fijo'] = pd.Series(np.where(df['cargo fijo'].isin([2.1,0.0]),df['cargo fijo'],None)).astype('category')\n",
    "df['diám. conex. ap.'] = pd.Series(np.where(df['diám. conex. ap.']<8,df['diám. conex. ap.'],None)).astype('category')\n",
    "\n",
    "#QUITAR CARACTERES RAROS QUE QUEDARON EN LUGAR DE LA BARRA EN MESFAC\n",
    "df.loc[ ~df.mesfac.str.contains('/'),'mesfac'] = df[ ~df.mesfac.str.contains('/') ].year + '/' + df[ ~df.mesfac.str.contains('/') ].mes\n",
    "\n",
    "#Convertir object a string[pyarrow]\n",
    "campos_object = df[df.columns[df.dtypes == 'object']].dtypes.keys().to_list()\n",
    "for col in campos_object:\n",
    "    df[col] = pd.Series(df[col], dtype=\"string[pyarrow]\")\n",
    "\n",
    "#Cambiar nombres a campos\n",
    "df.rename(columns={'tipo de tarifa':'categoria','tipo facturación':'metodo_consumo','diám. conex. ap.':'diam_con_ap'}, inplace=True)\n",
    "df.rename(columns={'lectura actual':'lectura_actual','lectura anterior':'lectura_anterior','consumo medido':'consumo_medido'}, inplace=True)\n",
    "df.rename(columns={'consumo facturado':'consumo_facturado','consumo promedo':'consumo_promedio','tipo facturación':'tipo_facturacion'}, inplace=True)\n",
    "df.rename(columns={'estado medidor':'estado_medidor','cl.instalación':'cl_inst','código hidráulico':'cod_hidraulico','fact. agua':'fact_agua'}, inplace=True)\n",
    "df.rename(columns={'fact. alcantari':'fact_alcantari','cargo fijo':'cargo_fijo','f.aguaprorrat':'fact_agua_pror','fact.alcantpror':'fact_alcan_pror'}, inplace=True)\n",
    "df.rename(columns={'prorrat. cargof':'pror_cargo_fijo','desc.anciano.ag':'desc_anciano_agua','desc.anciano.al':'desc_anciano_alcan'}, inplace=True)\n",
    "df.rename(columns={'desc.disc.agua':'desc_disc_agua','desc.disc.alcan':'desc_disc_alcan','des.socio.agua':'desc_socio_agua','desc.soci.alcan':'desc_socio_alcan'}, inplace=True)\n",
    "df.rename(columns={'desc.parro.agua':'desc_parro_agua','desc.parro.alca':'desc_parro_alcan','válido de':'valido_de','validez a':'validez_a'}, inplace=True)\n",
    "df.rename(columns={'fact.socioecono':'fact_socioecono','multasxcta':'multas_x_cta','inter. mora':'inter_mora','inter. financia':'inter_financia'}, inplace=True)\n",
    "df.rename(columns={'tasanomenclatur':'tasa_nomenc','corte':'corte','reconexión':'reconexion','instal. algua':'instal_algua','instal. alcant':'instal_alcan'}, inplace=True)\n",
    "df.rename(columns={'coactiva':'coactiva','otrosservicio':'otros_servicio'}, inplace=True)\n",
    "\n",
    "df.to_parquet(os.path.join(nombre_carpeta, 'df_raw2.parquet'))\n",
    "\n",
    "#CAMPOS DATASET VIEJO\n",
    "#'estcta':'estado','conact':'consumo','mancon':'tasa_admon','tasalc':'tasa_alcantarillado','valcon':'valor_cons_usd', 'valfac':'valor_facturado_usd'}, inplace=True)\n",
    "    \n",
    "#Unique values para campos con menos de 10 valores unique\n",
    "#df[ df.columns[(df.nunique()<10).tolist()] ].nunique()\n",
    "\n",
    "#campos_numericos = df[df.columns[(df.dtypes == 'int32') | (df.dtypes == 'int64') | (df.dtypes == 'float32') | (df.dtypes == 'float64')]].dtypes.keys().to_list()\n",
    "\n",
    "#Creamos Sample de rows cubriendo todos los meses y categorias\n",
    "df_sample = pd.DataFrame()\n",
    "for mes in df.mes.unique():\n",
    "    for cat in df.categoria.unique():\n",
    "        #Check if cat is not null or empty: cat was returning nan in some cases, this hack worked\n",
    "        if cat == cat:\n",
    "            sub_df = df[ (df.mes==mes) & (df.categoria == cat) ]\n",
    "            sample = sub_df.sample(min(500,sub_df.shape[0]))\n",
    "            df_sample = pd.concat([df_sample,sample])\n",
    "            \n",
    "#Sample de instalaciones (todas las facturaciones para cada instalacion parejo por categoria)\n",
    "#Remover cuentas con registros duplicados de facturaciones (combinaciones instalacion-mesfac repetidas)\n",
    "insts_remover = df[['instalacion','mesfac','consumo_medido']].groupby(['instalacion','mesfac']).agg('count').reset_index().query('consumo_medido>1').instalacion.unique().tolist()\n",
    "df_limpio = df[ ~df['instalacion'].isin(insts_remover) ]\n",
    "df_sample_inst_comp = pd.DataFrame()\n",
    "for cat in df_limpio.categoria.unique():\n",
    "    lista_insts = df_limpio.query(f'categoria==\"{cat}\"')['instalacion'].drop_duplicates().tolist()\n",
    "    #Remover instalaciones agregadas en otras categorías\n",
    "    if not df_sample_inst_comp.empty:\n",
    "        lista_insts = list( set(lista_insts) - set(df_sample_inst_comp.instalacion.tolist()) )\n",
    "    lista_insts = random.sample(lista_insts,min(10000,len(lista_insts)))\n",
    "    sub_df = df_limpio[ df_limpio.instalacion.isin(lista_insts) ]\n",
    "    df_sample_inst_comp = pd.concat([df_sample_inst_comp,sub_df])\n",
    "df_sample_inst_comp.to_parquet(os.path.join(nombre_carpeta, 'df_sample_inst_comp.parquet'))\n",
    "\n",
    "# CREACION DE DATASET DE FRAUDES A PARTIR DE DATA ORIGINAL\n",
    "df_fraudes = pd.read_excel(os.path.join(nombre_carpeta, 'multas_final_2021_2022.xlsx'),engine='openpyxl')\n",
    "df_fraudes = df_fraudes[['Cuenta contrato','Instalación','Fe.inic.extrema','Fecha entrada','Fecha fin real','Fe.inicio real','Código novedad','Causa Generación']]\n",
    "df_fraudes.rename(columns={'Cuenta contrato':'numcta','Instalación':'instalacion','Fe.inic.extrema':'fecha_multa','Fecha entrada':'fecha_entrada'}, inplace=True)\n",
    "df_fraudes.rename(columns={'Fecha fin real':'fecha_fin_real','Fe.inicio real':'fecha_inicio_real','Código novedad':'codigo_novedad','Causa Generación':'causa_generacion'}, inplace=True)\n",
    "df_fraudes = df_fraudes[ ~df_fraudes.instalacion.isnull() ]\n",
    "df_fraudes.instalacion = df_fraudes.instalacion.astype(int)\n",
    "df_fraudes.instalacion = df_fraudes.instalacion.astype(str)\n",
    "df_fraudes.fecha_multa=df_fraudes.fecha_multa.astype(str)\n",
    "\n",
    "df_fraudes['year']=df_fraudes['fecha_multa'].str[:4]\n",
    "df_fraudes['mes']=df_fraudes['fecha_multa'].str[5:7]\n",
    "df_fraudes['dia']=df_fraudes['fecha_multa'].str[8:10]\n",
    "df_fraudes['date']=  df_fraudes['year']+'/'+df_fraudes['mes']\n",
    "df_fraudes['mesmulta'] = df_fraudes['year']+'/'+df_fraudes['mes']\n",
    "df_fraudes.date = pd.to_datetime(df_fraudes.date)\n",
    "\n",
    "df_fraudes.to_parquet(os.path.join(nombre_carpeta, 'df_fraudes_raw.parquet'))\n",
    "\n",
    "list_inst_dataset = df_fraudes.instalacion.unique().tolist()\n",
    "df_fraudes_completo = df[ df['instalacion'].isin(list_inst_dataset) ].drop_duplicates(subset=['instalacion','mesfac'])\n",
    "cols = ['instalacion','mesmulta','codigo_novedad']\n",
    "df_fraudes_completo_etiquetado = df_fraudes_completo.merge(df_fraudes[cols], how = 'left', left_on = ['instalacion','mesfac'], \n",
    "                                                            right_on = ['instalacion','mesmulta'], indicator = True)\n",
    "df_fraudes_completo_etiquetado['is_fraud'] = np.where(df_fraudes_completo_etiquetado['codigo_novedad'].isnull(),0,1)\n",
    "# codigo_novedad>0 -> nunique encontró valores no nulos (NaN/None)\n",
    "facts_duplicados_fraudulentos = df_fraudes_completo_etiquetado.groupby(['instalacion','mesfac']).agg({'codigo_novedad':'nunique','mesmulta':'count'})\\\n",
    "    .reset_index().query('mesmulta>1 & codigo_novedad>0')[['instalacion','mesfac']].values.tolist()\n",
    "for f in facts_duplicados_fraudulentos:\n",
    "    df_fraudes_completo_etiquetado.loc[ (df_fraudes_completo_etiquetado['instalacion']==f[0]) & (df_fraudes_completo_etiquetado['mesfac']==f[1]),'is_fraud'] = 1\n",
    "df_fraudes_completo_etiquetado = df_fraudes_completo_etiquetado.drop_duplicates(subset=['instalacion','mesfac'])\n",
    "df_fraudes_completo_etiquetado['metodo_consumo'] = np.where(df_fraudes_completo_etiquetado.metodo_consumo=='Real',0,1)\n",
    "print(f'{df.shape} {df_fraudes.shape} {df_fraudes_completo_etiquetado.shape} {df_fraudes_completo_etiquetado._merge.value_counts()} {df_fraudes_completo_etiquetado.is_fraud.value_counts()}')\n",
    "\n",
    "## CONTROLAR SI HAY REGISTROS CON MES MULTA NO VACÍO PERO DISTINTO DE MESFAC (INCONSISTENTE)\n",
    "# df_comp_etiq.query('~mesmulta.isnull() & mesmulta!=mesfac').shape\n",
    "\n",
    "df_fraudes_completo_etiquetado.to_parquet(os.path.join(nombre_carpeta, 'df_fraudes_completo_etiquetado.parquet'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee30c41-98aa-4b1d-a1f0-6c2482990e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.99it/s]\n",
      "100%|██████████| 12/12 [06:34<00:00, 32.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# ARMADO DE DATA EN FORMATO WIDE\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "nombre_carpeta = '../../data/2022'\n",
    "df_fraudes_completo_etiquetado = pd.read_parquet(os.path.join(nombre_carpeta, 'df_fraudes_completo_etiquetado.parquet'))\n",
    "\n",
    "#Tabla fraudes\n",
    "fecha_fraud_list = df_fraudes_completo_etiquetado[(df_fraudes_completo_etiquetado.is_fraud==1)&(df_fraudes_completo_etiquetado.date>= '2022-01-01')]['date'].astype(str).unique().tolist()\n",
    "list_df = []\n",
    "for fecha_fraud in tqdm(fecha_fraud_list, total=len(fecha_fraud_list)):\n",
    "    df_etiquetado_fraud = df_fraudes_completo_etiquetado[df_fraudes_completo_etiquetado.date<=fecha_fraud].copy()\n",
    "    ctas_fraud = df_etiquetado_fraud[(df_etiquetado_fraud.date==fecha_fraud)&(df_etiquetado_fraud.is_fraud==1)].instalacion.unique().tolist()\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud[df_etiquetado_fraud.instalacion.isin(ctas_fraud)]\n",
    "    date_inicial = str(pd.to_datetime(fecha_fraud)- pd.DateOffset(months = 12))\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud[df_etiquetado_fraud['date']>=date_inicial]\n",
    "    # Obtenemos datos categóricos para la serie anterior al fraude, sin incluirlo\n",
    "    df_previo = df_etiquetado_fraud[ df_etiquetado_fraud['date']<fecha_fraud ]\n",
    "    df_cant_null = df_previo.groupby(['instalacion']).metodo_consumo.sum().reset_index(name='cant_consumo_est')\n",
    "    df_cant_estado = df_previo.groupby(['instalacion']).cl_inst.value_counts().unstack().reset_index()\n",
    "    df_cant_estado.columns = ['instalacion', 'cant_estado_0', 'cant_estado_1', 'cant_estado_2', 'cant_estado_3', 'cant_estado_4']\n",
    "    df_cant_estado.fillna(0, inplace=True)\n",
    "    df_categoria = df_previo.groupby(['instalacion']).categoria.apply(list).reset_index()\n",
    "    df_categoria[\"cant_categorias\"] = df_categoria.apply(lambda x: len(list(set(x[\"categoria\"]))) if isinstance(x[\"categoria\"],list) else 0,axis=1)\n",
    "    df_categoria[\"ult_categoria\"] = df_categoria.apply(lambda x: x[\"categoria\"][-1],axis=1)\n",
    "    \n",
    "    def cat_mas_freq(row):\n",
    "        serie = pd.Series(row[\"categoria\"])\n",
    "        if not serie.value_counts().empty:\n",
    "            return serie.value_counts().idxmax()\n",
    "        else:\n",
    "            return ''\n",
    "    df_categoria[\"categ_mas_frecuente\"] = df_categoria.apply(cat_mas_freq,axis=1)\n",
    "    def cambios_categ(row):\n",
    "        serie = pd.Series(row[\"categoria\"])\n",
    "        if not serie.value_counts().empty:\n",
    "            return serie.ne(serie.shift().bfill()).astype(int).sum()\n",
    "        else:\n",
    "            return 0\n",
    "    df_categoria[\"cambios_categoria\"] = df_categoria.apply(cambios_categ,axis=1)\n",
    "    \n",
    "    cols_ant = [str(x)+'_anterior' for x in range(12,-1,-1)]\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud.pivot_table(index=['instalacion'], columns=['date'] , values='consumo_medido')\n",
    "    df_etiquetado_fraud.columns = cols_ant\n",
    "    df_etiquetado_fraud['date_fiscalizacion'] = fecha_fraud\n",
    "    df_etiquetado_fraud.reset_index(inplace=True)\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud.merge(df_cant_null, on='instalacion')\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud.merge(df_cant_estado, on='instalacion')\n",
    "    df_etiquetado_fraud['mes']=mes=int(fecha_fraud[5:7])\n",
    "    df_etiquetado_fraud['bimestre']=(mes-1)//2+1\n",
    "    df_etiquetado_fraud['trimestre']=(mes-1)//3+1\n",
    "    df_etiquetado_fraud['cuatrimestre']=(mes-1)//4+1\n",
    "    df_etiquetado_fraud['semestre']=(mes-1)//6+1\n",
    "    df_etiquetado_fraud = df_etiquetado_fraud.merge(df_categoria.drop(columns=['categoria']), on='instalacion')\n",
    "    list_df.append(df_etiquetado_fraud)\n",
    "df_fraud_wide = pd.concat(list_df)\n",
    "\n",
    "#Datos de no fraude\n",
    "fecha_normal_list = df_fraudes_completo_etiquetado[(df_fraudes_completo_etiquetado.is_fraud==0)&(df_fraudes_completo_etiquetado.date>= '2022-01-01')]['date'].astype(str).unique().tolist()\n",
    "list_df_normal = []\n",
    "for fecha_normal in tqdm(fecha_normal_list, total=len(fecha_normal_list)):\n",
    "    df_etiquetado_normal = df_fraudes_completo_etiquetado[df_fraudes_completo_etiquetado.date<=fecha_normal].copy()\n",
    "    ctas_normal = df_etiquetado_normal[(df_etiquetado_normal.date==fecha_normal)&(df_etiquetado_normal.is_fraud==0)].instalacion.unique().tolist()\n",
    "    df_etiquetado_normal = df_etiquetado_normal[df_etiquetado_normal.instalacion.isin(ctas_normal)]\n",
    "    date_inicial = str(pd.to_datetime(fecha_normal)- pd.DateOffset(months = 12))\n",
    "    df_etiquetado_normal = df_etiquetado_normal[df_etiquetado_normal['date']>=date_inicial]\n",
    "    \n",
    "    # Obtenemos datos categóricos para la serie anterior al control, sin incluirlo\n",
    "    df_previo = df_etiquetado_normal[ df_etiquetado_normal['date']<fecha_normal ]\n",
    "    \n",
    "    df_cant_null = df_previo.groupby(['instalacion']).metodo_consumo.sum().reset_index(name='cant_consumo_est')\n",
    "    df_cant_estado = df_previo.groupby(['instalacion']).cl_inst.value_counts().unstack().reset_index()\n",
    "    df_cant_estado.columns = ['instalacion', 'cant_estado_0', 'cant_estado_1', 'cant_estado_2', 'cant_estado_3', 'cant_estado_4']\n",
    "    df_cant_estado.fillna(0, inplace=True)\n",
    "    \n",
    "    df_categoria = df_previo.groupby(['instalacion']).categoria.apply(list).reset_index()\n",
    "    df_categoria[\"cant_categorias\"] = df_categoria.apply(lambda x: len(list(set(x[\"categoria\"]))) if isinstance(x[\"categoria\"],list) else 0,axis=1)\n",
    "    df_categoria[\"ult_categoria\"] = df_categoria.apply(lambda x: x[\"categoria\"][-1],axis=1)\n",
    "    \n",
    "    def cat_mas_freq(row):\n",
    "        serie = pd.Series(row[\"categoria\"])\n",
    "        if not serie.value_counts().empty:\n",
    "            return serie.value_counts().idxmax()\n",
    "        else:\n",
    "            return ''\n",
    "    df_categoria[\"categ_mas_frecuente\"] = df_categoria.apply(cat_mas_freq,axis=1)\n",
    "    def cambios_categ(row):\n",
    "        serie = pd.Series(row[\"categoria\"])\n",
    "        if not serie.value_counts().empty:\n",
    "            return serie.ne(serie.shift().bfill()).astype(int).sum()\n",
    "        else:\n",
    "            return 0\n",
    "    df_categoria[\"cambios_categoria\"] = df_categoria.apply(cambios_categ,axis=1)\n",
    "    \n",
    "    cols_ant = [str(x)+'_anterior' for x in range(12,-1,-1)]\n",
    "    df_etiquetado_normal = df_etiquetado_normal.pivot_table(index=['instalacion'], columns=['date'] , values='consumo_medido')\n",
    "    df_etiquetado_normal.columns = cols_ant\n",
    "    df_etiquetado_normal['date_fiscalizacion'] = fecha_normal\n",
    "    df_etiquetado_normal.reset_index(inplace=True)\n",
    "    df_etiquetado_normal = df_etiquetado_normal.merge(df_cant_null, on='instalacion')\n",
    "    df_etiquetado_normal = df_etiquetado_normal.merge(df_cant_estado, on='instalacion')\n",
    "    \n",
    "    df_etiquetado_normal['mes']=mes=int(fecha_normal[5:7])\n",
    "    df_etiquetado_normal['bimestre']=(mes-1)//2+1\n",
    "    df_etiquetado_normal['trimestre']=(mes-1)//3+1\n",
    "    df_etiquetado_normal['cuatrimestre']=(mes-1)//4+1\n",
    "    df_etiquetado_normal['semestre']=(mes-1)//6+1\n",
    "    \n",
    "    df_etiquetado_normal = df_etiquetado_normal.merge(df_categoria.drop(columns=['categoria']), on='instalacion')\n",
    "    \n",
    "    list_df_normal.append(df_etiquetado_normal)\n",
    "\n",
    "df_normal_wide = pd.concat(list_df_normal)\n",
    "#Sacar fraudes\n",
    "df_normal_wide=df_normal_wide[~df_normal_wide.instalacion.isin(df_fraud_wide.instalacion.unique())]\n",
    "\n",
    "#Conservar solamente registros normales de las \n",
    "#fechas de fiscalización de los fraudes\n",
    "fechas_fraude_unicas = df_fraud_wide.date_fiscalizacion.unique().tolist()\n",
    "df_normal_wide = df_normal_wide[df_normal_wide.date_fiscalizacion.isin(fechas_fraude_unicas)]\n",
    "df_normal_wide['is_fraud']=0\n",
    "df_fraud_wide['is_fraud']=1\n",
    "#Otros filtros\n",
    "df_fraud_wide = df_fraud_wide[df_fraud_wide.cant_consumo_est<=6]\n",
    "df_normal_wide = df_normal_wide[df_normal_wide.cant_consumo_est==0]\n",
    "df_wide_normal_and_fraud = pd.concat([df_normal_wide,df_fraud_wide]).reset_index(drop=True)\n",
    "#La siguiente línea duplica los registros que tienen más de una categoría.. Hay que controlar eso\n",
    "#df_wide_normal_and_fraud = df_wide_normal_and_fraud.merge(df_fraudes_completo_etiquetado[['instalacion','categoria']].drop_duplicates(), on='instalacion')\n",
    "df_wide_normal_and_fraud['id'] = list(range(len(df_wide_normal_and_fraud)))\n",
    "\n",
    "df_wide_normal_and_fraud.to_parquet(os.path.join(nombre_carpeta, 'data_normal_and_frauds_wide.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd5dd54-2a01-4fe1-a95c-33b4082c45e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='44519'\n",
       "                  max='44519',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  44519\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n",
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='44519'\n",
       "                  max='44519',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  44519\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESADO DE NA'S Y EXTRACCIÓN DE FEATURES\n",
    "df = pd.read_parquet(os.path.join(nombre_carpeta, 'data_normal_and_frauds_wide.parquet'))\n",
    "df = df.rename(columns={'is_fraud':'target','id':'index'})\n",
    "variables_consumo = [x for x in df.columns if '_anterior' in x and x!='0_anterior']#sin 0_anterior (cons actual)#\n",
    "df.loc[:,['index']+variables_consumo] = llenar_val_vacios_ciclo(df.loc[:,['index']+variables_consumo], 12)\n",
    "df.loc[:,['index']+variables_consumo] = df.loc[:,['index']+variables_consumo].fillna(0)\n",
    "pipe_feature_engeniering_consumo = Pipeline(\n",
    "    [\n",
    "        (\"tsfel vars\", TsfelVars(features_names_path=None,num_periodos= 12)),\n",
    "        (\"add vars3\",  ExtraVars(num_periodos=3)),\n",
    "        (\"add vars6\",  ExtraVars( num_periodos=6)),\n",
    "        (\"add vars12\", ExtraVars(num_periodos=12)),\n",
    "    ]\n",
    "        )\n",
    "df_features = pipe_feature_engeniering_consumo.fit_transform(df[['index']+variables_consumo])\n",
    "cols_fs = ['index']+df_features.columns.tolist()[13:]\n",
    "df_completo = df.merge(df_features[cols_fs],how='inner',on=['index'],indicator=False)\n",
    "df_completo.to_parquet(os.path.join(nombre_carpeta, 'data_complete_wide_features.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bd46b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1655636, 52) (10433, 13) (221509, 56)\n",
      "CPU times: user 2.55 s, sys: 1.25 s, total: 3.8 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nombre_carpeta = '../../data/2022'\n",
    "#df = pd.read_parquet(os.path.join(nombre_carpeta, 'df_raw2.parquet'))\n",
    "#df_sample = pd.read_parquet(os.path.join(nombre_carpeta, 'df_sample.parquet'))\n",
    "#df_sample_chico = pd.read_parquet(os.path.join(nombre_carpeta, 'df_sample_chico.parquet'))\n",
    "df_sample_inst_comp = pd.read_parquet(os.path.join(nombre_carpeta, 'df_sample_inst_comp.parquet'))\n",
    "#Carga de registros de fraude\n",
    "df_fraudes = pd.read_parquet(os.path.join(nombre_carpeta, 'df_fraudes_raw.parquet'))\n",
    "df_fraudes_completo_etiquetado = pd.read_parquet(os.path.join(nombre_carpeta, 'df_fraudes_completo_etiquetado.parquet'))\n",
    "df_wide_normal_and_fraud = pd.read_parquet(os.path.join(nombre_carpeta, 'data_normal_and_frauds_wide.parquet'))\n",
    "print(f'{df_sample_inst_comp.shape} {df_fraudes.shape} {df_fraudes_completo_etiquetado.shape}')#{df.shape} {df.columns} {df_sample_chico.shape} {df_sample.shape} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782131fc-5a1a-4969-95f2-cef58ee2e3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CANTIDAD DE MULTAS POR CICLO\n",
    "#df_fraudes_completo_etiquetado[['ciclo', 'sector', 'ruta', 'manzana','secuencia', 'piso', 'departamento']].drop_duplicates().shape\n",
    "ciclos_multas = df_fraudes_completo_etiquetado.query('~codigo_novedad.isnull()')['ciclo']\n",
    "print(f'{ciclos_multas.shape} {ciclos_multas.nunique()} {ciclos_multas.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1870f8-f658-4393-a7cd-3d5b7da5ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CÓDIGOS DE VISUALIZACIONES\n",
    "#PAIRPLOT\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "campos_an = ['lectura_anterior','consumo_facturado','fact_agua','fact_alcantari','categoria']\n",
    "p1=sns.pairplot(df_sample_chico.reset_index()[ campos_an ],hue='categoria')\n",
    "plt.savefig(os.path.join(nombre_carpeta, 'fig.png'))\n",
    "\n",
    "#BOXPLOT Y LOG-BOXPLOT\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "df_sample_chico['consumo_medido_log'] = np.log10(df_sample_chico['consumo_medido']+1)\n",
    "ax = sns.boxplot(data = df_sample_chico, y= 'consumo_medido_log', x = 'categoria',palette='pastel')\n",
    "plt.savefig(os.path.join(nombre_carpeta, 'fig.png'))\n",
    "\n",
    "#BARPLOT CONSUMOS MEDIDOS PROMEDIO POR CATEGORIA\n",
    "df_agrupado = df[ (df['year']=='2022') & (df['mes'].astype('int')>6) ].groupby(['mes','tipo de tarifa'])['consumo medido'].agg('mean').reset_index()\n",
    "bar_plot = sns.barplot(data = df_agrupado, x = 'mes', y = 'consumo medido', hue = 'tipo de tarifa') #c = df_agrupado['tipo de tarifa'].map(colors)) #kind='bar', ax=ax, \n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#Promedio de Consumo por mes por cl.instalación\n",
    "df_agrupado = df_sample.groupby(['mesfac','cl_inst'])['consumo_medido'].agg('mean').reset_index()\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "bar_plot = sns.barplot(data = df_agrupado, x = 'mesfac', y = 'consumo_medido', hue = 'cl_inst')\n",
    "for item in bar_plot.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#DISTRIBUCIÓN DE CONSUMO MEDIDO POR CATEGORÍA\n",
    "sns.displot(data=df_sample_chico.sample(1000), x='consumo_medido', hue='categoria')#, ax=axs[0])\n",
    "plt.savefig(os.path.join(nombre_carpeta, 'fig.png'))\n",
    "\n",
    "#HEATMAP CORRELACIÓN ENTRE VARIABLES NUMÉRICAS\n",
    "campos_an = ['lectura_anterior','consumo_facturado','fact_agua','fact_alcantari','categoria']\n",
    "sns.heatmap(df_sample_chico[campos_an].corr(),cmap='RdBu_r', annot=True, vmin=-1, vmax=1)\n",
    "plt.savefig(os.path.join(nombre_carpeta, 'fig.png'))\n",
    "\n",
    "#HEATMAP DIAM CONEX VS. CATEGORIA\n",
    "gr = df_sample_chico[['instalacion','diam_con_ap','categoria']].drop_duplicates()\n",
    "cr = pd.crosstab(gr.diam_con_ap,gr.categoria)#, normalize='all'\n",
    "bar_plot = sns.heatmap(cr,annot=False)\n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#LINEPLOT SERIES DE TIEMPO\n",
    "campo = 'instalacion'#'numcta'\n",
    "list_ctas = random.sample(list(df[campo].unique()),10)\n",
    "df_gr = df[ df[campo].isin(list_ctas) ][[campo,'mesfac','consumo_medido']].pivot(index=campo,columns='mesfac',values='consumo_medido').reset_index()\n",
    "sns.lineplot(data=df_gr[df_gr.columns[1:]].transpose(),legend=False)\n",
    "\n",
    "#MEDIAS MÓVILES DE CONSUMO MEDIDO POR PERÍODO Y CATEGORÍA\n",
    "df_sample_filtrado = pd.DataFrame()\n",
    "for cat in df_sample_inst_comp.categoria.unique():\n",
    "    if cat == cat:\n",
    "        lista_insts = random.sample(list(df_sample_inst_comp.query(f'categoria == \"{cat}\"').instalacion.unique()),10)\n",
    "        sub_df = df_sample_inst_comp[ df_sample_inst_comp.instalacion.isin(lista_insts) ]\n",
    "        df_sample_filtrado = pd.concat([df_sample_filtrado,sub_df])\n",
    "df_sample_filtrado = df_sample_filtrado.sort_values('mesfac')\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "bar_plot = sns.lineplot(data=df_sample_filtrado,x='mesfac',y='consumo_medido',hue='categoria',legend=True)\n",
    "for item in bar_plot.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#CANTIDAD DE MULTAS POR MES Y CATEGORIA\n",
    "df_fraudes['mes_multa'] = df_fraudes['Fe.inic.extrema'].astype('str').str[:7]\n",
    "df_fraudes_fraude = df_fraudes[ ~df_fraudes['Código novedad'].isnull() ].groupby(['mes_multa','Tipo.Tarifa']).size().reset_index(name='Cantidad')\n",
    "sns.set(rc={'figure.figsize':(16,12)})\n",
    "bar_plot = sns.barplot(data = df_fraudes_fraude, x = 'mes_multa', y = 'Cantidad', hue = 'Tipo.Tarifa')\n",
    "for item in bar_plot.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#Diferente consumo medido y facturado\n",
    "#(AGRUPAR PARA VER SI EL TIPO DE FACTURACIÓN ES ESTIMADA, VERSUS REAL CUANDO SON IGUALES)\n",
    "cons_diferentes = df[ df['consumo_medido'] != df['consumo_facturado'] ].groupby(['categoria','mesfac']).size().reset_index(name='Cantidad')\n",
    "cons_diferentes['categoria'] = cons_diferentes['categoria'].cat.remove_categories([\"IND\",\"PUB\",\"SAL\",\"MUN\",\"OFI\"])\n",
    "cons_diferentes = cons_diferentes[ ~cons_diferentes['categoria'].isnull() ]\n",
    "sns.set(rc={'figure.figsize':(8,4)})\n",
    "bar_plot = sns.barplot(data = cons_diferentes, x = 'mesfac', y = 'Cantidad', hue = 'categoria')\n",
    "for item in bar_plot.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "fig = bar_plot.get_figure()\n",
    "fig.savefig(f'{nombre_carpeta}/fig.png')\n",
    "\n",
    "#Para verificar por grupos la cantidadde NAs\n",
    "#df[['year','mes','tipo de tarifa','consumo medido']].drop(columns = ['year','mes','tipo de tarifa']).isna().groupby(df[['year','mes','tipo de tarifa']]).sum().reset_index()\n",
    "#Verificar que columnas tienen valores null\n",
    "#df.columns[df.isna().any()].tolist()\n",
    "#df.isnull().sum()\n",
    "#df_year_completo = (df.groupby(['numcta', 'year'])['mes'].size()).reset_index(name='Count')#.head(50) #ningún año tiene las fechas completas\n",
    "\n",
    "#VERIFICAR CATEGORIAS ASIGNADAS A CUENTAS O INSTALACIONES (CANTIDAD POR CADA UNA)\n",
    "campo = 'instalacion'#'numcta'\n",
    "list_ctas = random.sample(list(df[campo].unique()),100000)\n",
    "df_gr = df[ df[campo].isin(list_ctas) ][['numcta','instalacion','categoria','cl_inst','mesfac','consumo_medido']]\\\n",
    "    .groupby(campo).agg('nunique').reset_index()#.query('categoria>1')\n",
    "print(df_gr.shape)\n",
    "print(df_gr.head())\n",
    "print('----')\n",
    "print(f'Distinct CL_INST: {df_gr.cl_inst.value_counts()}')\n",
    "print('----')\n",
    "print(f'Distinct CATEGORIA: {df_gr.categoria.value_counts()}')\n",
    "\n",
    "#CUENTA DE INSTALACIONES POR CATEGORIA Y CL_INST\n",
    "df_sample_inst_comp[['instalacion','cl_inst','categoria','numcta']].drop_duplicates().groupby(['cl_inst','categoria'])[['instalacion']].count().unstack().head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
